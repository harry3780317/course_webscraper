Index: smallscrape.py
IDEA additional info:
Subsystem: com.intellij.openapi.diff.impl.patch.BaseRevisionTextPatchEP
<+>import requests\r\nfrom requests.exceptions import HTTPError, Timeout\r\nfrom selenium import webdriver\r\n##from selenium.webdriver.chrome.options import Options\r\n## params = year/term/dept/search_param\r\n\r\nMATCH_LIST = [\"fall\", \"spring\", \"summer\"]\r\nOUTLINE_BASE_URL = \"http://www.sfu.ca/outlines.html?\"\r\n##CHROME_PATH = \"D:\\chromedriver_win32\\chromedriver.exe\" # need install chrome driver for selenium to work https://chromedriver.chromium.org/downloads\r\n\r\n##input(\"list out courses format: year/<fall|spring|summer> \\n or search course format: year/<fall|spring|summer>/search_wildcard\")\r\ndef checkInputParams():\r\n    while True:\r\n        input_params = \"2019/fall/eng\"  ## for testing purpose, please change to user input\r\n        if input_params:\r\n            parse_in = input_params.split(\"/\")\r\n            if len(parse_in) < 2:\r\n                continue\r\n\r\n            if not parse_in[0].isnumeric or parse_in[1].lower() not in MATCH_LIST:\r\n                continue\r\n            query_str = \"http://www.sfu.ca/bin/wcm/course-outlines?year={}&term={}\".format(parse_in[0],\r\n                                                                                           parse_in[1].lower())\r\n            if len(parse_in) == 3:\r\n                query_str += \"&search={}\".format(parse_in[2])\r\n            getResp(query_str)\r\n            break\r\n\r\ndef getResp(query_str):\r\n    try:\r\n        res = requests.get(query_str, timeout=5)\r\n        res.raise_for_status()\r\n        jsonRes = res.json()\r\n        print(\"FULL RESPONSE\\n\\n\")\r\n        print(jsonRes)\r\n        print(\"\\n\\nONLY GET VALUE\\n\\n\")\r\n        for value in jsonRes:\r\n            print(value[\"value\"])\r\n\r\n    except HTTPError as httperror:\r\n        print(f\"http error raised: code: {httperror}\")\r\n    except Timeout as timeout:\r\n        print(f\"http error timed out: code: {timeout}\")\r\n    except Exception as excep:\r\n        print(f\"exception raised: code: {excep}\")\r\n\r\ndef scrapeOutline(suffix_val):\r\n    furl = OUTLINE_BASE_URL + suffix_val\r\n    driver = webdriver.Chrome()\r\n    driver.get(furl)\r\n    owelems = driver.find_element_by_class_name(\"overview-list\").find_elements_by_tag_name(\"li\")\r\n    for owelem in owelems:\r\n        attrib = owelem.get_attribute(\"class\")\r\n        if attrib == \"course-times\" or attrib == \"exam-times\":\r\n            p = owelem.text\r\n            print(p)\r\n        elif attrib == \"instructor\":\r\n            instr = owelem.text\r\n            print(instr)\r\n        elif attrib == \"prereq\":\r\n            prereq = owelem.text\r\n            print(prereq)\r\n    caldescr = driver.find_element_by_xpath(\"//h4[contains(text(),'CALENDAR DESCRIPTION:')]/following-sibling::p\")\r\n    print(caldescr.text)\r\n    coursedet = driver.find_element_by_xpath(\"//h4[contains(text(),'COURSE DETAILS:')]/following-sibling::p\")\r\n    print(coursedet.text)\r\n    glists = driver.find_element_by_class_name(\"grading-items\").find_elements_by_tag_name(\"li\")\r\n    for glist in glists:\r\n        one = glist.find_element_by_class_name(\"one\")\r\n        two = glist.find_element_by_class_name(\"two\")\r\n        print(one.text)\r\n        print(two.text)\r\n    material = driver.find_element_by_xpath(\"//h4[contains(text(),'MATERIALS + SUPPLIES:')]/following-sibling::p\")\r\n    print(material.text)\r\n    reqreading = driver.find_element_by_xpath(\"//h4[contains(text(),'REQUIRED READING:')]/following-sibling::div\")\r\n    print(reqreading.text)\r\n    driver.close()\r\n\r\nscrapeOutline(\"2020/spring/math/100/d200\")\r\n
Subsystem: com.intellij.openapi.diff.impl.patch.CharsetEP
<+>UTF-8
===================================================================
diff --git a/smallscrape.py b/smallscrape.py
--- a/smallscrape.py	(revision cd41fffe90c2e76d665c11ace5cbb13a48ecc3b3)
+++ b/smallscrape.py	(date 1613252421310)
@@ -2,40 +2,57 @@
 from requests.exceptions import HTTPError, Timeout
 from selenium import webdriver
 ##from selenium.webdriver.chrome.options import Options
-## params = year/term/dept/search_param
-
+## params = year/term/dept/coursenum
+## i.e 2019/spring/cmpt/300
 MATCH_LIST = ["fall", "spring", "summer"]
 OUTLINE_BASE_URL = "http://www.sfu.ca/outlines.html?"
 ##CHROME_PATH = "D:\chromedriver_win32\chromedriver.exe" # need install chrome driver for selenium to work https://chromedriver.chromium.org/downloads
 
-##input("list out courses format: year/<fall|spring|summer> \n or search course format: year/<fall|spring|summer>/search_wildcard")
-def checkInputParams():
+##input("list out courses format: year/<fall|spring|summer> \n or search course format: year/<fall|spring|summer>/dept/coursenumber")
+
+def parseInputParams():
+
     while True:
-        input_params = "2019/fall/eng"  ## for testing purpose, please change to user input
+        input_params = input("search for class in format of year/term/dept/coursenum: ")
         if input_params:
             parse_in = input_params.split("/")
-            if len(parse_in) < 2:
+            if len(parse_in) < 4:
+                print("need exactly four arguments i.e in the format of year/term/dept/coursenum")
+                continue
+            if not parse_in[0].isnumeric():
+                print("year should be numeric i.e 2019")
+                continue
+            if parse_in[1].lower() not in MATCH_LIST:
+                print("terms must be exactly one of fall|spring|summer")
+                continue
+            if any(i.isdigit() for i in parse_in[2]):
+                print("dept cannot contain numbers")
                 continue
-
-            if not parse_in[0].isnumeric or parse_in[1].lower() not in MATCH_LIST:
+            if not parse_in[3].isnumeric():
+                print("coursenumber should be numeric i.e 300")
                 continue
-            query_str = "http://www.sfu.ca/bin/wcm/course-outlines?year={}&term={}".format(parse_in[0],
-                                                                                           parse_in[1].lower())
-            if len(parse_in) == 3:
-                query_str += "&search={}".format(parse_in[2])
-            getResp(query_str)
-            break
+            return [parse_in[0], parse_in[1].lower(),parse_in[2],parse_in[3]]
 
-def getResp(query_str):
+def getResp(query_list):
+
+    query_str = "http://www.sfu.ca/bin/wcm/course-outlines?year={}&term={}&search={}%20{}".format(query_list[0],
+                                                                                                  query_list[1],
+                                                                                                  query_list[2],
+                                                                                                  query_list[3])
+    print("related results: \n")
+    suffix_list = []
     try:
         res = requests.get(query_str, timeout=5)
         res.raise_for_status()
         jsonRes = res.json()
-        print("FULL RESPONSE\n\n")
-        print(jsonRes)
-        print("\n\nONLY GET VALUE\n\n")
         for value in jsonRes:
-            print(value["value"])
+            suffix_str = value["value"]
+            ls = suffix_str.split("/")
+            if len(ls) < 5:
+                continue
+            if ls[3] != query_list[3]:
+                continue
+            suffix_list.append(suffix_str)
 
     except HTTPError as httperror:
         print(f"http error raised: code: {httperror}")
@@ -43,37 +60,43 @@
         print(f"http error timed out: code: {timeout}")
     except Exception as excep:
         print(f"exception raised: code: {excep}")
+    return suffix_list
 
-def scrapeOutline(suffix_val):
-    furl = OUTLINE_BASE_URL + suffix_val
-    driver = webdriver.Chrome()
-    driver.get(furl)
-    owelems = driver.find_element_by_class_name("overview-list").find_elements_by_tag_name("li")
-    for owelem in owelems:
-        attrib = owelem.get_attribute("class")
-        if attrib == "course-times" or attrib == "exam-times":
-            p = owelem.text
-            print(p)
-        elif attrib == "instructor":
-            instr = owelem.text
-            print(instr)
-        elif attrib == "prereq":
-            prereq = owelem.text
-            print(prereq)
-    caldescr = driver.find_element_by_xpath("//h4[contains(text(),'CALENDAR DESCRIPTION:')]/following-sibling::p")
-    print(caldescr.text)
-    coursedet = driver.find_element_by_xpath("//h4[contains(text(),'COURSE DETAILS:')]/following-sibling::p")
-    print(coursedet.text)
-    glists = driver.find_element_by_class_name("grading-items").find_elements_by_tag_name("li")
-    for glist in glists:
-        one = glist.find_element_by_class_name("one")
-        two = glist.find_element_by_class_name("two")
-        print(one.text)
-        print(two.text)
-    material = driver.find_element_by_xpath("//h4[contains(text(),'MATERIALS + SUPPLIES:')]/following-sibling::p")
-    print(material.text)
-    reqreading = driver.find_element_by_xpath("//h4[contains(text(),'REQUIRED READING:')]/following-sibling::div")
-    print(reqreading.text)
+def scrapeOutline(suffix_list):
+
+    driver = webdriver.Chrome()
+    for suffix_val in suffix_list:
+        if suffix_val:
+            furl = OUTLINE_BASE_URL + suffix_val
+            driver.get(furl)
+            owelems = driver.find_element_by_class_name("overview-list").find_elements_by_tag_name("li")
+            for owelem in owelems:
+                attrib = owelem.get_attribute("class")
+                if attrib == "course-times" or attrib == "exam-times":
+                    p = owelem.text
+                    print(p)
+                elif attrib == "instructor":
+                    instr = owelem.text
+                    print(instr)
+                elif attrib == "prereq":
+                    prereq = owelem.text
+                    print(prereq)
+            caldescr = driver.find_element_by_xpath("//h4[contains(text(),'CALENDAR DESCRIPTION:')]/following-sibling::p")
+            print(caldescr.text)
+            coursedet = driver.find_element_by_xpath("//h4[contains(text(),'COURSE DETAILS:')]/following-sibling::p")
+            print(coursedet.text)
+            glists = driver.find_element_by_class_name("grading-items").find_elements_by_tag_name("li")
+            for glist in glists:
+                one = glist.find_element_by_class_name("one")
+                two = glist.find_element_by_class_name("two")
+                print(one.text)
+                print(two.text)
+            material = driver.find_element_by_xpath("//h4[contains(text(),'MATERIALS + SUPPLIES:')]/following-sibling::p")
+            print(material.text)
+            reqreading = driver.find_element_by_xpath("//h4[contains(text(),'REQUIRED READING:')]/following-sibling::div")
+            print(reqreading.text)
     driver.close()
 
-scrapeOutline("2020/spring/math/100/d200")
+out = getResp(parseInputParams())
+print(out)
+#scrapeOutline(out)
